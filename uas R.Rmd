---
title: "uas R"
author: "Kelompok 1"
date: "2023-12-19"
output: html_document
---

## IMPORT LIBRARY
```{r}
library(dplyr)
library(ggplot2)
library(caret)
library(tidyverse)
library(psych) #Untuk melihat data normal
library(moments) #Untuk menghitung Pearson Kurtosis, Geary Skewness
library(outliers) #Untuk mendeteksi outliers
library(Metrics)
library(randomForest)
library(e1071)
library(janitor)
library(shiny)
library(shinythemes)
library(class)
library(gbm)
library(pROC)
library(rpart)
library(rpart.plot)
```

## LOADING DATASET
```{r}

admisi = read.csv('admisi.csv', header = TRUE, sep = ";")
admisi
profiling = read.csv('profiling.csv', header = TRUE, sep = ";")
profiling

```



## DATA PREPROCESSING 1: HANDLING MISSING VALUE
```{r}

# Cek Nilai NA
cek_NA_GRE = sum(is.na(admisi$GRE))
cek_NA_TOEFL = sum(is.na(admisi$TOEFL))
cek_NA_MLETTER = sum(is.na(admisi$MOT_LETTER))
cek_NA_RLETTER = sum(is.na(admisi$REKOM_LETTER))
cek_NA_LULUS = sum(is.na(admisi$LULUS))
cek_NA_USIA = sum(is.na(profiling$USIA))
cek_NA_JENKEL = sum(is.na(profiling$JENIS_KEL))
cek_NA_RUA = sum(is.na(profiling$Raking_Uni_Asal))
cek_NA_IPK = sum(is.na(profiling$IPK))
cek_NA_RISET = sum(is.na(profiling$RISET))

# Menghitung modus
modus_jenkel = names(sort(table(profiling$JENIS_KEL), decreasing = TRUE)[1])
modus_riset = names(sort(table(profiling$RISET), decreasing = TRUE)[1])
modus_lulus = names(sort(table(admisi$LULUS), decreasing = TRUE)[1])

# Mengganti nilai NA dengan modus
profiling$JENIS_KEL[is.na(profiling$JENIS_KEL)] = modus_jenkel
profiling$RISET[is.na(profiling$RISET)] = modus_riset
profiling$RISET[profiling$RISET == ''] = modus_riset
admisi$LULUS[is.na(admisi$LULUS)] = modus_lulus

# Transformasi faktor
profiling$JENIS_KEL = as.factor(profiling$JENIS_KEL)
admisi$LULUS = factor(admisi$LULUS, levels = c(1, 0), labels = c('Lulus', 'Tidak Lulus'))
profiling$RISET = as.factor(profiling$RISET)

# Mengganti koma (,) dengan titik (.) pada kolom "IPK"
profiling$IPK = gsub(",", ".", profiling$IPK)
admisi$MOT_LETTER = gsub(",", ".", admisi$MOT_LETTER)
admisi$REKOM_LETTER <- gsub(",", ".", admisi$REKOM_LETTER)

# Mengganti nilai NA pada nilai non-numerik
profiling$IPK = as.numeric(profiling$IPK)
admisi$MOT_LETTER = as.numeric(admisi$MOT_LETTER)
admisi$REKOM_LETTER = as.numeric(admisi$REKOM_LETTER)

# Menghitung mean
mean_rank = mean(profiling$Ranking_Uni_Asal, na.rm = TRUE)
mean_motl = mean(admisi$MOT_LETTER, na.rm = TRUE)
mean_koml = mean(admisi$REKOM_LETTER, na.rm = TRUE)

# Mengganti nilai NA dengan mean
profiling$Ranking_Uni_Asal[is.na(profiling$Ranking_Uni_Asal)] = mean_rank
admisi$MOT_LETTER[is.na(admisi$MOT_LETTER)] = mean_motl
admisi$REKOM_LETTER[is.na(admisi$REKOM_LETTER)] = mean_koml

str(admisi)
str(profiling)

```


## DATA PREPROCESSING 2A: HANDLING DUPLICATED DATA ADMISI
```{R}

# Cek Data Duplikat
cek_admisi = get_dupes(admisi)
cek_admisi

# Mempertahankan satu baris dari setiap kelompok duplikat
newdata_admisi = distinct(admisi, .keep_all = TRUE)

```


## DATA PREPROCESSING 2B: HANDLING DUPLICATED DATA PROFILING
```{r}

# Cek Data Duplikat
cek_profiling = get_dupes(profiling)
cek_profiling

# Mempertahankan satu baris dari setiap kelompok duplikat
newdata_profiling = distinct(profiling, .keep_all = TRUE)

```


## DATA PREPROCESSING 3A: HANDLING OUTLIER ADMISI

```{r}

# Loop untuk menampilkan boxplot satu per satu untuk variabel numerik
for (col in names(newdata_admisi)) {
  if (is.numeric(newdata_admisi[[col]])) {
    boxplot(newdata_admisi[[col]], main = col)
  }
}

# Menghapus Outliers
IQR_koml = IQR(newdata_admisi$REKOM_LETTER)
lowfen_koml = quantile(newdata_admisi$REKOM_LETTER, 0.25) - 1.5 * IQR_koml

clean_admisi = subset(newdata_admisi, REKOM_LETTER >= lowfen_koml)

# Mengecek apakah masih terdapat outliers
for (col in names(clean_admisi)) {
  if (is.numeric(clean_admisi[[col]])) {
    boxplot(clean_admisi[[col]], main = col)
  }
}

```



## DATA PREPROCESSING 3B: HANDLING OUTLIER PROFILING

```{r}

# Loop untuk menampilkan boxplot satu per satu untuk variabel numerik
for (col in names(newdata_profiling)) {
  if (is.numeric(newdata_profiling[[col]])) {
    boxplot(newdata_profiling[[col]], main = col)
  }
}

# Menghapus Outliers
IQR_ipk = IQR(newdata_profiling$IPK)
upfen_ipk = quantile(newdata_profiling$IPK, 0.75) + 1.5 * IQR_ipk

clean_profiling = subset(newdata_profiling, IPK <= upfen_ipk)

# Mengecek apakah masih terdapat outliers
for (col in names(clean_profiling)) {
  if (is.numeric(clean_profiling[[col]])) {
    boxplot(clean_profiling[[col]], main = col)
  }
}

```


## MERGE DATASET
```{r}

# Menggabungkan dataset berdasarkan kolom ID
newdata = merge(clean_profiling, clean_admisi, by = "ID")
newdata

```


## FEATURE SELECTION
```{r}

control = trainControl(method="repeatedcv", number=10, repeats=3)
model = train(LULUS ~ ., data = newdata[, setdiff(names(newdata), "NAMA")], method = "lvq", preProcess = "scale", trControl = control)

# Estimasi Feature yang Penting
importance = varImp(model, scale=FALSE)

# plot importance
plot(importance)

```

## SPLIT DATA
```{r}
# Subset data dengan feature yang dipilih
selected_features <- c("IPK", "RISET", "GRE", "TOEFL", "REKOM_LETTER", "MOT_LETTER", "JENIS_KEL", "USIA")
selected_data <- newdata[, c("LULUS", selected_features)]

# Convert categorical variables to factors
selected_data$JENIS_KEL <- as.factor(selected_data$JENIS_KEL)

# Split the data into training and testing sets
set.seed(123)  # for reproducibility
train_indices <- createDataPartition(selected_data$LULUS, p = 0.8, list = FALSE)
train_data <- selected_data[train_indices, ]
test_data <- selected_data[-train_indices, ]

```


## Model 1 (RF)
```{r}
# Model Training
rf_model <- train(LULUS ~ .,  
                         data = train_data, 
                         method = "rf",
                         trControl = trainControl(method = "cv", number = 5))

# Model Prediction on the test set
predictions_rf <- predict(rf_model, newdata = test_data)

# Calculate AUC and plot ROC
roc_curve <- roc(test_data$LULUS, as.numeric(predictions_rf))
auc_value <- auc(roc_curve)

# Evaluate the model
conf_matrix <- confusionMatrix(predictions_rf, test_data$LULUS)
accuracy_rf <- conf_matrix$overall["Accuracy"]
precision_rf <- conf_matrix$byClass[["Pos Pred Value"]]

# Display evaluation metrics
print(paste("Random Forest Accuracy:", accuracy_rf))
print(paste("Random Forest Precision:", precision_rf))
print(paste("Random Forest AUC:", auc_value))

# Plot ROC curve
plot(roc_curve, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
```

## MODEL 2 (SVM)
```{r}
# Model Training - Support Vector Machine (SVM)
svm_model <- svm(LULUS ~ ., data = train_data, probability = TRUE)

# Model Prediction on the test set
predictions_svm <- predict(svm_model, newdata = test_data, probability = TRUE)

# Extracting probability of positive class for AUC calculation
svm_probabilities <- attr(predictions_svm, "probabilities")[, 2]

# Evaluate the model
conf_matrix_svm <- confusionMatrix(predictions_svm, test_data$LULUS)
accuracy_svm <- conf_matrix_svm$overall["Accuracy"]
precision_svm <- conf_matrix_svm$byClass[["Pos Pred Value"]]

# Calculate AUC and plot ROC
roc_curve_svm <- roc(test_data$LULUS, svm_probabilities)
auc_value_svm <- auc(roc_curve_svm)

# Display evaluation metrics for SVM
print(paste("SVM Accuracy:", accuracy_svm))
print(paste("SVM Precision:", precision_svm))
print(paste("SVM AUC:", auc_value_svm))

# Plot ROC curve
plot(roc_curve_svm, main = "ROC Curve for SVM", col = "blue", lwd = 2)
```

## Model 3 (LR)
```{r}
# Convert "Lulus" to 1 and "Tidak Lulus" to 0
train_data_lr <- train_data %>%
  mutate(LULUS = ifelse(LULUS == "Lulus", 1, 0))

# Model Training - Logistic Regression (LR)
lr_model <- glm(LULUS ~ ., data = train_data_lr, family = "binomial")

# Model Prediction on the test set
predictions_lr <- predict(lr_model, newdata = test_data, type = "response")

# Convert predicted probabilities to class labels
predicted_classes_lr <- ifelse(predictions_lr > 0.5, "Lulus", "Tidak Lulus")

# Evaluate the model
conf_matrix_lr <- confusionMatrix(factor(predicted_classes_lr), test_data$LULUS)
accuracy_lr <- conf_matrix_lr$overall["Accuracy"]
precision_lr <- conf_matrix_lr$byClass[["Pos Pred Value"]]

# Calculate AUC and plot ROC
roc_curve_lr <- roc(test_data$LULUS, predictions_lr)
auc_value_lr <- auc(roc_curve_lr)

# Display evaluation metrics for LR
print(paste("LR Accuracy:", accuracy_lr))
print(paste("LR Precision:", precision_lr))
print(paste("LR AUC:", auc_value_lr))

# Plot ROC curve
plot(roc_curve_lr, main = "ROC Curve for Logistic Regression", col = "blue", lwd = 2)
```

## Model 4 (GBM)
```{r}
# Convert "Lulus" to 1 and "Tidak Lulus" to 0
train_data_gbm <- train_data %>%
  mutate(LULUS = ifelse(LULUS == "Lulus", 1, 0))

# Model Training - Gradient Boosting Machine (GBM)
gbm_model <- gbm(LULUS ~ ., data = train_data_gbm, distribution = "bernoulli", n.trees = 100, interaction.depth = 3)

# Model Prediction on the test set
predictions_gbm <- predict(gbm_model, newdata = test_data, n.trees = 100)

# Convert predicted values to probabilities
probabilities_gbm <- 1 / (1 + exp(-predictions_gbm))

# Convert predicted probabilities to class labels
predicted_classes_gbm <- ifelse(probabilities_gbm > 0.5, "Lulus", "Tidak Lulus")

# Evaluate the model
conf_matrix_gbm <- confusionMatrix(factor(predicted_classes_gbm), test_data$LULUS)
accuracy_gbm <- conf_matrix_gbm$overall["Accuracy"]
precision_gbm <- conf_matrix_gbm$byClass[["Pos Pred Value"]]

# Calculate AUC and plot ROC
roc_curve_gbm <- roc(test_data$LULUS, probabilities_gbm)
auc_value_gbm <- auc(roc_curve_gbm)

# Display evaluation metrics for GBM
print(paste("GBM Accuracy:", accuracy_gbm))
print(paste("GBM Precision:", precision_gbm))
print(paste("GBM AUC:", auc_value_gbm))

# Plot ROC curve
plot(roc_curve_gbm, main = "ROC Curve for Gradient Boosting Machine", col = "blue", lwd = 2)
```

## MODEL 5 (DT)
```{r}
# Convert "Lulus" to 1 and "Tidak Lulus" to 0
train_data_dt <- train_data %>%
  mutate(LULUS = ifelse(LULUS == "Lulus", 1, 0))

# Model Training - Decision Tree (DT)
dt_model <- rpart(LULUS ~ ., data = train_data_dt, method = "class")

# Model Prediction on the test set
predictions_dt <- predict(dt_model, newdata = test_data, type = "class")

# Convert predicted class to labels
predicted_classes_dt <- ifelse(predictions_dt == 1, "Lulus", "Tidak Lulus")

# Evaluate the model
conf_matrix_dt <- confusionMatrix(factor(predicted_classes_dt), test_data$LULUS)
accuracy_dt <- conf_matrix_dt$overall["Accuracy"]
precision_dt <- conf_matrix_dt$byClass[["Pos Pred Value"]]

# Display evaluation metrics for Decision Tree
print(paste("Decision Tree Accuracy:", accuracy_dt))
print(paste("Decision Tree Precision:", precision_dt))

# Create ROC curve
roc_curve_dt <- roc(test_data$LULUS, as.numeric(predictions_dt))
auc_value_dt <- auc(roc_curve_dt)

# Display AUC for Decision Tree
print(paste("Decision Tree AUC:", auc_value_dt))

# Plot ROC curve
plot(roc_curve_dt, main = "ROC Curve for Decision Tree", col = "blue", lwd = 2)
```


## MODEL 6 (KNN)
```{r}

# Preprocess the data
preProcValues <- preProcess(train_data, method = c("center", "scale"))
trainTransformed <- predict(preProcValues, train_data)
testTransformed <- predict(preProcValues, test_data)

# Train the model
knnModel <- train(
		     LULUS ~ ., 
		     data = trainTransformed, 
		     method = "knn", 
		     trControl = trainControl(method = "cv"), 
		     tuneGrid = expand.grid(k=1:100))

# Train K-Nearest Neighbors with the best k
best_model<- knn3(
                  LULUS ~ .,
                  data = trainTransformed,
                  k = knnModel$bestTune$k
                 )

# Make predictions on the test set
predictions_knn <- predict(best_model, testTransformed,type = "prob")
probabilities_knn <- as.numeric(predictions_knn[, "Lulus"])

# Calculate confusion matrix
conf_matrix_knn <- confusionMatrix(factor(ifelse(probabilities_knn > 0.5, "Lulus", "Tidak Lulus")), testTransformed$LULUS)
accuracy_knn <- conf_matrix_knn$overall["Accuracy"]
precision_knn <- conf_matrix_knn$byClass[["Pos Pred Value"]]

# Display evaluation metrics for k-NN
print(paste("K-Nearest Neighbors Accuracy:", accuracy_knn))
print(paste("K-Nearest Neighbors Precision:", precision_knn))

# Create ROC curve
roc_curve_knn <- roc(testTransformed$LULUS, probabilities_knn)
auc_value_knn <- auc(roc_curve_knn)

# Display AUC for k-NN
print(paste("K-Nearest Neighbors AUC:", auc_value_knn))

# Plot ROC curve for k-NN
plot(roc_curve_knn, main = "ROC Curve for k-NN", col = "blue", lwd = 2)


```
## HASIL NARASI

# Presisi dalam konteks ini merujuk pada proporsi dari prediksi positif yang benar (True Positive) dibandingkan dengan total prediksi positif (True Positive + False Positive). Dalam kata lain, presisi mengukur sejauh mana prediksi positif yang diberikan oleh model benar atau relevan. Dalam kasus ini, IEDU ingin memastikan bahwa ketika alat prediktif memberikan saran untuk melanjutkan aplikasi MBA di UoU, prediksi tersebut memiliki tingkat ketepatan yang tinggi, minimal 85%.

# Confusion matrix adalah alat evaluasi kinerja model yang menyajikan hasil prediksi dalam empat kategori: True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FN).
# True Positive (TP):
# Definisi: Jumlah observasi yang sebenarnya positif dan diprediksi positif dengan benar.
# Konteks: Jumlah calon mahasiswa yang benar-benar berhasil di UoU dan diprediksi dengan benar oleh model.

# False Positive (FP):
# Definisi: Jumlah observasi yang sebenarnya negatif tetapi diprediksi positif.
# Konteks: Jumlah calon mahasiswa yang sebenarnya tidak berhasil di UoU, tetapi model memprediksi bahwa mereka berhasil.

# True Negative (TN):
# Definisi: Jumlah observasi yang sebenarnya negatif dan diprediksi negatif dengan benar.
# Konteks: Jumlah calon mahasiswa yang tidak berhasil di UoU dan model dengan benar memprediksi bahwa mereka tidak berhasil.

# False Negative (FN):
# Definisi: Jumlah observasi yang sebenarnya positif tetapi diprediksi negatif.
# Konteks: Jumlah calon mahasiswa yang sebenarnya berhasil di UoU, tetapi model gagal memprediksi keberhasilan mereka.

# Presisi memberikan gambaran seberapa akurat model dalam mengidentifikasi calon mahasiswa yang sebenarnya berhasil di UoU dari total calon yang diprediksi berhasil. Dalam konteks ini, IEDU menetapkan target presisi sebesar 85%, yang berarti ingin meminimalkan jumlah prediksi positif yang salah

# Features yang diambil yaitu IPK, RISET, GRE, TOEFL, REKOM_LETTER, MOT_LETTER, JENIS_KEL, USIA

# IPK : bisa menjadi indikator kuat untuk kinerja akademis calon mahasiswa. IPK cenderung berkorelasi dengan keberhasilan studi lanjutan.
# RISET : RISET atau pengalaman penelitian dapat mencerminkan dedikasi dan keterampilan penelitian calon mahasiswa. Terutama jika program MBA di UoU memiliki fokus pada aspek riset.
# GRE dan TOEFL : Skor GRE dan TOEFL bisa menjadi standart untuk melihat kemampuan akademis dan kemahiran berbahasa inggris calon mahasiswa. Keduanya dianggap penting dalam penilaian dan kelayakan penerimaan.
# REKOM_LETTER dan MOT_LETTER : Skor surat rekomendasi dan motivation letter memberikan wawasan tentang kemampuan interpersonal dan motivasi calon mahasiswa. 
# JENIS_KEL dan USIA : Jenis kelamin dan usia memberikan informasi tambahan tentang karakteristik pendaftar. Meskipun label ini tergantung dengan kebijakan masing-masing universitas. Tetapi tetap features ini membantu dalam memberikan korelasi dan peran dalam nilai yang dihasilkan dalam akurasi, presisi, dan AUC pada model.

# Penggunaan Logistic Regression
# Model LR cocok digunakan dalam kasus binomial 
# Dalam model ini juga digunakan Trade-off Threshold dimana dengan menentukan ambang batas. Dengan menggunakan ambang batas 0.5, kita membuat keputusan biner untuk menentukan kategori kelas. Nilai ambang batas dapat disesuaikan tergantung pada preferensi atau kebutuhan spesifik dalam menentukan seberapa tinggi probabilitas harus untuk dianggap sebagai kelas positif. Digunakan untuk memberikan label kelas berdasarkan kondisi tertentu. Jika nilai probabilitas prediksi lebih besar dari 0.5, maka siswa dianggap "Lulus", dan jika tidak, dianggap "Tidak Lulus".
# Setelah membandingkan beberapa model, LR memiliki akurasi dan presisi yang sangat baik. Dengan Akuarasi 96.64% yang artinya model bisa memprediksi apakah seorang siswa bisa lulus atau tidak lulus dengan tingkat keakuratan tinggi. Kemudian, Presisi mencapai 93.10%, hal ini menunjukkan bahwa dari semua prediksi yang dikategorikan model, sekitar 93.10% diantaranya benar-benar merupakan kasus siswa yang lulus. Presisi tinggi menyimpulkan dan mengindikasikan bahwa model cenderung memberikan prediksi positif yang besar.
# AUC yang tinggi dengan nilai 0.9964. AUC yang mendekati 1 menunjukkan bahwa model mempunyai kemampuan yang sangat baik dalam membedakan antara kelas "LULUS" dan "TIDAK LULUS". (Sebenarnya, AUC yang nilainya diatas 0.5 sudah bagus tetapi akan sangat baik bila mendekati 1)
# Berdasarkan analisis ROC Curve, Grafik ROC Curve menunjukkan bahwa model Logistic Regression memiliki tingkat True Positive Rate (Sensitivity) yang tinggi dan tingkat False Positive Rate yang rendah. Ini menggambarkan kemampuan model dalam mengidentifikasi siswa yang lulus tanpa terlalu banyak membuat kesalahan memprediksi siswa yang sebenarnya tidak lulus.
# Pemilihan model LR juga karena ruang kosong dikiri atas kurva paling kecil diantara kurva model lain, semakin kecil ruangnya, semakin baik hasilnya.
# AUC mewakili nilai numerik dibawah kurva ROC. Semakin besar luas dibawah ROC dan semakin besar skor AUC maka model semakin baik (mendekati 1).


## SHINY
```{r}
jenis_kel_levels <- levels(test_data$JENIS_KEL)
riset_levels <- levels(test_data$RISET)

ui <- fluidPage(
  theme = shinytheme("superhero"),
  tags$head(
    tags$style(
      HTML("
        .container-fluid {
          border-radius: 15px;  /* Set the radius as needed */
          overflow: hidden;
        }
      ")
    )
  ),
  titlePanel(HTML('<div style="text-align: center; color: white;">IEDU PREDICTION TOOL</div>')),
  HTML('<p style="text-align: center; color: white;">Dibuat oleh Kelompok 1</p>'),
  br(),
  fluidRow(
    column(4, align = "center",
      img(src = "https://i.pinimg.com/564x/cd/71/07/cd710729ea3e0c9059d49025459b4087.jpg", width = 300,
          height = 400, class = "rounded-image"),
      br(),
      br(),
      img(src = "https://i.pinimg.com/564x/a2/bc/97/a2bc974da36f6345334dde79cf77287e.jpg", width = 300,
              height = 300, class = "rounded-image")
    ),
    column(8,
      fluidRow(
        column(6, align = "center", 
          textInput('NAMA', 'Masukkan Nama Anda'),
          selectInput('JENIS_KEL', 'Pilih Jenis Kelamin Anda', 
                      choices = jenis_kel_levels, 
                      selected = jenis_kel_levels[1]),
          numericInput('USIA', 'Pilih Usia Anda', 
                       min = 10,
                       max = 50,
                       value = 20),
          numericInput('IPK', 'Masukkan IPK Anda : ', 
                       value = 3, 
                       min = 1, 
                       max = 4, 
                       step = 0.01),
          numericInput('TOEFL','Masukan Skor TOEFL Anda : ', 
                       value=100, 
                       min = 50, 
                       max = 200),
          numericInput('GRE','Masukan Skor Gre Anda : ', 
                       value=300, 
                       min = 260, 
                       max = 340),
          numericInput('REKOM_LETTER','Masukan Skor REKOM_LETTER Anda : ', 
                       value = 4, 
                       min = 1, 
                       max = 5, 
                       step = 0.05),
          numericInput('MOT_LETTER','Masukan Skor MOT_LETTER Anda : ', 
                       value = 4, 
                       min = 1, 
                       max = 5, 
                       step = 0.05),
          selectInput('RISET', 'Apakah Anda Melakukan Riset Sebelumnya', 
                      choices = riset_levels, 
                      selected = riset_levels[1]),
          actionButton('hitung', 'Prediksi Kelulusan', style = "margin-top: 20px;")  
        ),
        column(6, align = "center", 
          
          br(),
          img(src = "https://i.pinimg.com/564x/1f/10/d2/1f10d2f3841a9463f82ce425a8df861f.jpg", width = 300,
              height = 300, class = "rounded-image"),
          br(),
          br(),
          img(src = "https://i.pinimg.com/564x/6a/37/f6/6a37f6866ec3d712ab7cbb8a331a2323.jpg", width = 300,
              height = 400, class = "rounded-image"),
          br(),
        )
      )
    )
  ),
  mainPanel(
    textOutput('hasil')
  ),
  id = "iedu-tool"  
)
server = function(input, output, session) {
  observeEvent(input$hitung, {
    predictions <- predict(lr_model, newdata=data.frame(JENIS_KEL=input$JENIS_KEL, USIA=input$USIA, 
                                                     IPK=input$IPK, TOEFL=input$TOEFL, GRE=input$GRE, 
                                                     REKOM_LETTER=input$REKOM_LETTER,
                                                     MOT_LETTER=input$MOT_LETTER,
                                                     RISET=input$RISET))
    
   # Menentukan label output berdasarkan prediksi
  output_label <- ifelse(predictions > 0.5, paste("SELAMAT", input$NAMA, ", ANDA LULUS"), 
                       paste("MOHON MAAF", input$NAMA, ", ANDA BELUM LULUS"))

  # Menentukan warna latar belakang berdasarkan hasil prediksi
  background_color <- ifelse(predictions > 0.5, "green", "red")

  # Menyiapkan HTML dengan inline CSS untuk mengatur warna latar belakang dan menengahkan teks
  hasil_html <- sprintf('<div style="background-color:%s; padding:20px; border-radius: 10px; text-align: center;">%s</div>', background_color, output_label)

  # Menampilkan hasil di halaman baru dengan HTML
  showModal(modalDialog(
    HTML(hasil_html),
    easyClose = TRUE,
    footer = NULL
    ))
  })
}

shinyApp(ui = ui, server = server)
```